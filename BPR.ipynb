{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Personalized Ranking, provided at Xiangnan He, Neural Collaborative Filtering as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Reference: \n",
    "#Factor = 8, HitRate = 0.63, NDCG = 0.36\n",
    "#Factor = 16, HR = 0.66, NDCG = 0.39\n",
    "#Factor = 32, HR = 0.68, NDCG = 0.41\n",
    "#Factor = 64, HR = 0.68, NDCG = 0.41-0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with open('train_data.txt', 'r') as infile:\n",
    "    for l in infile:\n",
    "        l.rstrip('\\n')\n",
    "        intl = [int(x) for x in l.split(',')]\n",
    "        train_data.append(intl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_user = 6040\n",
    "num_item = np.max([u[1] for u in train_data])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [0 for i in range(6040)]\n",
    "with open('test_data.txt','r') as infile:\n",
    "    for l in infile:\n",
    "        l.rstrip('\\n')\n",
    "        intl = [int(x) for x in l.split(',')]\n",
    "        test_data[intl[0]] = intl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pair = [[] for i in range(6040)]\n",
    "with open('negative_pairs.txt','r') as infile:\n",
    "    for l in infile:\n",
    "        l.rstrip('\\n')\n",
    "        u,i = (int(x) for x in l.split(','))\n",
    "        negative_pair[u].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the data\n",
    "item_of_user = [[] for i in range(6040)]\n",
    "for d in train_data:\n",
    "    item_of_user[d[0]].append(d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size):\n",
    "    u_batch, i_batch, j_batch = [], [], []\n",
    "    for i in range(batch_size):\n",
    "        u = np.random.randint(0, num_user)\n",
    "        i = np.random.randint(0, len(item_of_user[u]))\n",
    "        pi = item_of_user[u][i]\n",
    "        j = np.random.randint(0, num_item)\n",
    "        while j in item_of_user[u]:\n",
    "            j = np.random.randint(0, num_item)\n",
    "        u_batch.append(u)\n",
    "        i_batch.append(pi)\n",
    "        j_batch.append(j)\n",
    "    return u_batch, i_batch, j_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 320\n",
    "learning_rate = 0.01\n",
    "regularization_rate = 0.01\n",
    "latent_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "gamma_u = tf.get_variable(name = \"latent-u\", shape = [num_user, latent_size], initializer = tf.truncated_normal_initializer(stddev = 0.01))\n",
    "gamma_i = tf.get_variable(name = 'latent-i', shape = [num_item, latent_size], initializer = tf.truncated_normal_initializer(stddev = 0.01))\n",
    "#gamma_u = tf.get_variable(name = 'latent_u', shape = [num_user, latent_size], initializer = tf.constant_initializer(0.5))\n",
    "#gamma_i = tf.get_variable(name = 'latent_i', shape = [num_user, latent_size], initializer = tf.constant_initializer(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = tf.contrib.layers.l2_regularizer(regularization_rate)\n",
    "U = tf.placeholder(tf.int32, [None])\n",
    "I = tf.placeholder(tf.int32, [None])\n",
    "J = tf.placeholder(tf.int32, [None])\n",
    "latent_batch_u = tf.nn.embedding_lookup(gamma_u, U)\n",
    "latent_batch_i = tf.nn.embedding_lookup(gamma_i, I)\n",
    "latent_batch_j = tf.nn.embedding_lookup(gamma_i, J)\n",
    "x_uij = tf.reduce_sum(tf.multiply(latent_batch_u, latent_batch_i-latent_batch_j), 1)\n",
    "#neg_mark = tf.einsum('ij,ij->i', latent_batch_u, latent_batch_j)\n",
    "#x_uij = tf.nn.sigmoid(pos_mark-neg_mark)\n",
    "regu = regularizer(latent_batch_u) + regularizer(latent_batch_i)+regularizer(latent_batch_j)\n",
    "loss = regu - tf.reduce_sum(tf.log(tf.nn.sigmoid(x_uij)))\n",
    "train_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "#evaluation_score = tf.reduce_sum(tf.multiply(latent_batch_u, latent_batch_j), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from time import *\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.9 s] After 0 epochs, loss is 221.806656 while regularize term is 0.002841\n",
      "[9.1 s]After 0 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.102649 and 0.046341\n",
      "[8.9 s] After 1 epochs, loss is 221.773712 while regularize term is 0.005744\n",
      "[9.3 s]After 1 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.257285 and 0.150447\n",
      "[8.9 s] After 2 epochs, loss is 220.004700 while regularize term is 0.134422\n",
      "[9.4 s]After 2 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.479636 and 0.271850\n",
      "[8.8 s] After 3 epochs, loss is 184.451553 while regularize term is 2.751644\n",
      "[9.4 s]After 3 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.482119 and 0.271683\n",
      "[8.9 s] After 4 epochs, loss is 138.154495 while regularize term is 6.824976\n",
      "[9.4 s]After 4 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.479801 and 0.271746\n",
      "[8.9 s] After 5 epochs, loss is 107.790703 while regularize term is 9.415101\n",
      "[9.5 s]After 5 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.479139 and 0.271798\n",
      "[8.9 s] After 6 epochs, loss is 104.864059 while regularize term is 9.056862\n",
      "[9.4 s]After 6 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.485099 and 0.274672\n",
      "[8.9 s] After 7 epochs, loss is 107.026024 while regularize term is 9.067677\n",
      "[9.5 s]After 7 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.487252 and 0.275329\n",
      "[8.9 s] After 8 epochs, loss is 104.480240 while regularize term is 9.475239\n",
      "[9.4 s]After 8 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.488576 and 0.277083\n",
      "[8.9 s] After 9 epochs, loss is 104.762970 while regularize term is 9.822207\n",
      "[9.4 s]After 9 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.491556 and 0.280180\n",
      "[8.9 s] After 10 epochs, loss is 91.320854 while regularize term is 10.134153\n",
      "[9.5 s]After 10 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.498675 and 0.282522\n",
      "[9.0 s] After 11 epochs, loss is 90.159073 while regularize term is 9.998323\n",
      "[9.6 s]After 11 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.508278 and 0.288582\n",
      "[8.8 s] After 12 epochs, loss is 103.816605 while regularize term is 10.081593\n",
      "[9.4 s]After 12 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.515894 and 0.293895\n",
      "[8.9 s] After 13 epochs, loss is 96.352592 while regularize term is 10.461693\n",
      "[9.5 s]After 13 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.525166 and 0.298670\n",
      "[8.9 s] After 14 epochs, loss is 100.263069 while regularize term is 10.595832\n",
      "[9.5 s]After 14 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.530464 and 0.304125\n",
      "[8.9 s] After 15 epochs, loss is 99.556702 while regularize term is 11.130104\n",
      "[9.6 s]After 15 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.540232 and 0.309650\n",
      "[8.9 s] After 16 epochs, loss is 86.670601 while regularize term is 12.005692\n",
      "[9.5 s]After 16 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.545033 and 0.311821\n",
      "[8.9 s] After 17 epochs, loss is 81.084053 while regularize term is 11.901474\n",
      "[9.5 s]After 17 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.549338 and 0.314421\n",
      "[8.9 s] After 18 epochs, loss is 87.822899 while regularize term is 12.235198\n",
      "[9.5 s]After 18 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.560596 and 0.322126\n",
      "[8.9 s] After 19 epochs, loss is 83.492569 while regularize term is 12.513259\n",
      "[9.5 s]After 19 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.563907 and 0.324446\n",
      "[8.9 s] After 20 epochs, loss is 77.113159 while regularize term is 13.085543\n",
      "[9.5 s]After 20 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.569536 and 0.326724\n",
      "[8.8 s] After 21 epochs, loss is 81.539825 while regularize term is 13.308739\n",
      "[9.4 s]After 21 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.578146 and 0.331729\n",
      "[8.9 s] After 22 epochs, loss is 80.575653 while regularize term is 13.509250\n",
      "[9.5 s]After 22 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.580960 and 0.332085\n",
      "[8.9 s] After 23 epochs, loss is 85.632561 while regularize term is 13.974362\n",
      "[9.5 s]After 23 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.585927 and 0.336243\n",
      "[9.0 s] After 24 epochs, loss is 93.568817 while regularize term is 14.459853\n",
      "[9.6 s]After 24 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.589735 and 0.336884\n",
      "[8.9 s] After 25 epochs, loss is 78.246529 while regularize term is 14.250508\n",
      "[9.5 s]After 25 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.596026 and 0.344798\n",
      "[8.9 s] After 26 epochs, loss is 67.195618 while regularize term is 14.784922\n",
      "[9.5 s]After 26 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.597185 and 0.343849\n",
      "[8.9 s] After 27 epochs, loss is 78.042770 while regularize term is 15.027551\n",
      "[9.5 s]After 27 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.599007 and 0.345447\n",
      "[10.1 s] After 28 epochs, loss is 85.206894 while regularize term is 15.366217\n",
      "[10.8 s]After 28 epochs and 3105 iterations, hit@10 and NDCG@10 is 0.607450 and 0.351315\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c1335e1c55c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_records\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mbatch_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_j\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m#print(xuij)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-6814e3deccd2>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mu_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_of_user\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_of_user\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(num_epochs):\n",
    "        t1 = time()\n",
    "        for j in range(num_records//batch_size):\n",
    "            batch_u,batch_i, batch_j = get_batch(batch_size)\n",
    "            _, reg_term, loss_value = sess.run([train_optimizer, regu, loss], feed_dict = {U:batch_u, I:batch_i, J:batch_j})\n",
    "            #print(xuij)\n",
    "        print(\"[%.1f s] After %d epochs, loss is %f while regularize term is %f\"%(time()-t1, i, loss_value, reg_term))\n",
    "        #test it using the negative pairs\n",
    "        gamma_u_val = gamma_u.eval()\n",
    "        gamma_i_val = gamma_i.eval()\n",
    "        #if i==0: \n",
    "        #    print(gamma_u_val[0])\n",
    "        #if i==10:\n",
    "        #    print(gamma_u_val[0])\n",
    "        \n",
    "        \n",
    "        hits = 0\n",
    "        tNDCG = 0 \n",
    "        for k in range(num_user):\n",
    "            map_item_rating = {}\n",
    "            maxScore = np.dot(gamma_u_val[k], gamma_i_val[test_data[k]])\n",
    "            map_item_rating[test_data[k]] = maxScore\n",
    "            early_stop = False\n",
    "            countLarger = 0\n",
    "            for m in range(100):\n",
    "                _score = np.dot(gamma_u_val[k], gamma_i_val[negative_pair[k][m]])\n",
    "                map_item_rating[negative_pair[k][m]] = _score\n",
    "                \n",
    "                if _score>maxScore:\n",
    "                    countLarger +=1\n",
    "                \n",
    "                if countLarger >=10:\n",
    "                    early_stop = True\n",
    "                    break\n",
    "            if early_stop == False:\n",
    "                ranklist = heapq.nlargest(10, map_item_rating, key = map_item_rating.get)\n",
    "                if test_data[k] in ranklist:\n",
    "                    hits += 1\n",
    "                    idx = ranklist.index(test_data[k])\n",
    "                    tNDCG += log(2)/log(idx+2)\n",
    "                        \n",
    "                \n",
    "        print(\"[%.1f s]After %d epochs and %d iterations, hit@10 and NDCG@10 is %f and %f\"%(time()-t1,i,j, hits/6040.0, tNDCG/6040.0))\n",
    "        #with tf.device('/cpu'):\n",
    "        #    if i%10 == 0:\n",
    "        #        saver = tf.train.Saver()\n",
    "        #        saver.save(sess, \"Model/model.ckpt\", global_step = i)\n",
    "                    \n",
    "                        \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
