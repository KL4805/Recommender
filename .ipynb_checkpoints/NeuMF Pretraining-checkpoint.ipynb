{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import heapq\n",
    "from time import time\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with open('train_data.txt','r') as infile:\n",
    "    for l in infile:\n",
    "        l.rstrip('\\n')\n",
    "        lint = [int(x) for x in l.split(',')]\n",
    "        train_data.append(lint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_of_user = [[] for i in range(6040)]\n",
    "for l in train_data:\n",
    "    u = l[0]\n",
    "    item = l[1]\n",
    "    item_of_user[u].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "with open('test_data.txt','r') as infile:\n",
    "    for l in infile:\n",
    "        l.rstrip('\\n')\n",
    "        lint = [int(x) for x in l.split(',')]\n",
    "        test_data.append(lint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pair = [[] for i in range(6040)]\n",
    "with open('negative_pairs.txt','r') as infile:\n",
    "    for l in infile:\n",
    "        l.rstrip('\\n')\n",
    "        u,i = (int(x) for x in l.split(','))\n",
    "        negative_pair[u].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user = 6040\n",
    "num_item = 3952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this task, we are performing a regression-like task, therefore the batch contains users, items and labels. \n",
    "def get_data(negative_num):\n",
    "    batch_user, batch_item, batch_label = [], [], []\n",
    "    for u in range(num_user):\n",
    "        for it in item_of_user[u]:\n",
    "            batch_user.append(u)\n",
    "            batch_item.append(it)\n",
    "            batch_label.append(1)\n",
    "            sampled_negative = 0\n",
    "            while sampled_negative <negative_num:\n",
    "                j = np.random.randint(num_item)\n",
    "                if j in item_of_user[u]:\n",
    "                    continue\n",
    "                else:\n",
    "                    batch_user.append(u)\n",
    "                    batch_item.append(j)\n",
    "                    batch_label.append(0)\n",
    "                    sampled_negative += 1\n",
    "    \n",
    "    return np.array(batch_user), np.array(batch_item), np.array(batch_label)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMF_latent_size = 32\n",
    "MLP_latent_size = 32\n",
    "learning_rate = 0.0005\n",
    "max_epochs = 20\n",
    "MLP_layers = [64, 32, 16, 8]\n",
    "#MLP_layers[0] = 2*MLP_latent_size\n",
    "regularization_rate = 1e-20\n",
    "batch_size = 256\n",
    "negative_ratio = 4\n",
    "\n",
    "alpha = 0.5\n",
    "# the tradeoff between GMF and MLP final output weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "GMF_embedding_u = tf.get_variable(name = \"GMF_latent_u\", shape = [num_user, GMF_latent_size])\n",
    "GMF_embedding_i = tf.get_variable(name = \"GMF_latent_i\", shape = [num_item, GMF_latent_size])\n",
    "GMF_weight = tf.get_variable(name = \"GMF_weight\", shape = [GMF_latent_size, 1])\n",
    "\n",
    "\n",
    "MLP_embedding_u = tf.get_variable(name = \"MLP_latent_u\", shape = [num_user, MLP_latent_size])\n",
    "MLP_embedding_i = tf.get_variable(name = \"MLP_latent_i\", shape = [num_item, MLP_latent_size])\n",
    "\n",
    "MLP_hidden_weights = []\n",
    "MLP_hidden_biases = []\n",
    "for i in range(len(MLP_layers) - 1):\n",
    "    MLP_hidden_weights.append(tf.get_variable(name = 'MLP_hidden_w' + str(i), shape = [MLP_layers[i], MLP_layers[i+1]]))\n",
    "    MLP_hidden_biases.append(tf.get_variable(name = \"MLP_hidden_b\" + str(i), shape = [MLP_layers[i+1]]))\n",
    "\n",
    "MLP_output = tf.get_variable(name = 'MLP_output_w', shape = [MLP_layers[-1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = tf.placeholder(tf.int32, [None])\n",
    "I = tf.placeholder(tf.int32, [None])\n",
    "label = tf.placeholder(tf.int32, [None])\n",
    "regularizer = tf.contrib.layers.l2_regularizer(regularization_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GMF_part\n",
    "GMF_embedded_u = tf.nn.embedding_lookup(GMF_embedding_u, U)\n",
    "GMF_embedded_i = tf.nn.embedding_lookup(GMF_embedding_i, I)\n",
    "\n",
    "GMF_merged_ui = tf.multiply(GMF_embedded_u, GMF_embedded_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP_part\n",
    "MLP_embedded_u = tf.nn.embedding_lookup(MLP_embedding_u, U)\n",
    "MLP_embedded_i = tf.nn.embedding_lookup(MLP_embedding_i, I)\n",
    "\n",
    "MLP_merged_ui = tf.concat([MLP_embedded_u, MLP_embedded_i], axis = 1)\n",
    "\n",
    "hidden_in = MLP_merged_ui\n",
    "\n",
    "for i in range(len(MLP_layers) - 1):\n",
    "    hidden_out = tf.nn.relu(tf.matmul(hidden_in, MLP_hidden_weights[i]) + MLP_hidden_biases[i])\n",
    "    hidden_in = hidden_out\n",
    "    tf.add_to_collection(\"losses\", regularizer(MLP_hidden_weights[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_concat = tf.concat([GMF_merged_ui, hidden_out], axis = 1)\n",
    "total_weight = tf.concat([GMF_weight*alpha, (1-(alpha))*MLP_output], axis = 0)\n",
    "output = tf.reshape(tf.matmul(final_concat, total_weight), [-1])\n",
    "prediction = tf.nn.sigmoid(output)\n",
    "reg_term = regularizer(GMF_embedding_u) +regularizer(GMF_embedding_i) + regularizer(MLP_embedding_u) + regularizer(MLP_embedding_i)\n",
    "reg_term += tf.add_n(tf.get_collection(\"losses\"))\n",
    "loss = reg_term + tf.losses.log_loss(labels = label, predictions = prediction)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from GMFModel/model.ckpt-14\n",
      "INFO:tensorflow:Restoring parameters from MLPModel/model.ckpt-16\n",
      "[69.1 s] After 0 epochs, loss on batch is 0.169.\n",
      "[74.2 s] After 0 epochs, hit@10 = 0.713, NDCG@10 = 0.429.\n",
      "[83.6 s] After 1 epochs, loss on batch is 0.205.\n",
      "[90.2 s] After 1 epochs, hit@10 = 0.714, NDCG@10 = 0.431.\n",
      "[76.7 s] After 2 epochs, loss on batch is 0.232.\n",
      "[81.4 s] After 2 epochs, hit@10 = 0.715, NDCG@10 = 0.430.\n",
      "[67.6 s] After 3 epochs, loss on batch is 0.192.\n",
      "[72.4 s] After 3 epochs, hit@10 = 0.714, NDCG@10 = 0.432.\n",
      "[66.7 s] After 4 epochs, loss on batch is 0.199.\n",
      "[71.4 s] After 4 epochs, hit@10 = 0.717, NDCG@10 = 0.434.\n",
      "[70.9 s] After 5 epochs, loss on batch is 0.160.\n",
      "[75.6 s] After 5 epochs, hit@10 = 0.715, NDCG@10 = 0.432.\n",
      "[73.0 s] After 6 epochs, loss on batch is 0.188.\n",
      "[77.8 s] After 6 epochs, hit@10 = 0.717, NDCG@10 = 0.434.\n",
      "[68.5 s] After 7 epochs, loss on batch is 0.190.\n",
      "[73.3 s] After 7 epochs, hit@10 = 0.720, NDCG@10 = 0.434.\n",
      "[77.8 s] After 8 epochs, loss on batch is 0.204.\n",
      "[84.7 s] After 8 epochs, hit@10 = 0.717, NDCG@10 = 0.433.\n",
      "[68.6 s] After 9 epochs, loss on batch is 0.161.\n",
      "[73.6 s] After 9 epochs, hit@10 = 0.714, NDCG@10 = 0.432.\n",
      "[74.0 s] After 10 epochs, loss on batch is 0.225.\n",
      "[79.3 s] After 10 epochs, hit@10 = 0.714, NDCG@10 = 0.430.\n",
      "[76.7 s] After 11 epochs, loss on batch is 0.231.\n",
      "[82.8 s] After 11 epochs, hit@10 = 0.717, NDCG@10 = 0.432.\n",
      "[78.0 s] After 12 epochs, loss on batch is 0.186.\n",
      "[84.4 s] After 12 epochs, hit@10 = 0.715, NDCG@10 = 0.432.\n",
      "[73.7 s] After 13 epochs, loss on batch is 0.194.\n",
      "[78.8 s] After 13 epochs, hit@10 = 0.714, NDCG@10 = 0.432.\n",
      "[73.1 s] After 14 epochs, loss on batch is 0.222.\n",
      "[78.6 s] After 14 epochs, hit@10 = 0.715, NDCG@10 = 0.432.\n",
      "[72.6 s] After 15 epochs, loss on batch is 0.202.\n",
      "[77.2 s] After 15 epochs, hit@10 = 0.713, NDCG@10 = 0.431.\n",
      "[71.3 s] After 16 epochs, loss on batch is 0.238.\n",
      "[86.8 s] After 16 epochs, hit@10 = 0.709, NDCG@10 = 0.429.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b1dc6b898c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mbi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #load the pretrained weights\n",
    "    best_hr = 0\n",
    "    saver1 = tf.train.Saver([GMF_embedding_u, GMF_embedding_i, GMF_weight])\n",
    "    saver2 = tf.train.Saver([MLP_embedding_u, MLP_embedding_i] + MLP_hidden_weights + MLP_hidden_biases + [MLP_output])\n",
    "    saver1.restore(sess, \"GMFModel/model.ckpt-14\")\n",
    "    saver2.restore(sess, \"MLPModel/model.ckpt-16\")\n",
    "    #print(GMF_embedding_u.eval())\n",
    "    for ep in range(max_epochs):\n",
    "        t1 = time()\n",
    "        eu, ei, el = get_data(negative_ratio)\n",
    "        for j in range(len(eu)//batch_size):\n",
    "            sample = np.random.randint(len(eu), size = batch_size)\n",
    "            bu = eu[sample]\n",
    "            bi = ei[sample]\n",
    "            bl = el[sample]\n",
    "            loss_value, _ = sess.run([loss, optimizer], feed_dict = {U:bu, I:bi, label:bl})\n",
    "        \n",
    "        t2 = time()\n",
    "        print(\"[%.1f s] After %d epochs, loss on batch is %.3f.\"%(t2-t1, ep, loss_value))\n",
    "        \n",
    "        hits = 0\n",
    "        tNDCG = 0\n",
    "        for u in range(num_user):\n",
    "            map_item_rating = {}\n",
    "            maxScore = sess.run(output, feed_dict = {U:np.array([u]), I:np.array([test_data[u][1]])})\n",
    "            negative_i = negative_pair[u]\n",
    "            negative_u = [u for m in range(100)]\n",
    "            negative_score = sess.run(output, feed_dict = {U:negative_u, I:negative_i})\n",
    "            map_item_rating[test_data[u][1]] = maxScore\n",
    "            for k in range(100):\n",
    "                map_item_rating[negative_i[k]] = negative_score[k]\n",
    "            ranklist = heapq.nlargest(10, map_item_rating, key = map_item_rating.get)\n",
    "            if test_data[u][1] in ranklist:\n",
    "                hits +=1\n",
    "                idx = ranklist.index(test_data[u][1])\n",
    "                tNDCG += log(2)/log(idx+2)\n",
    "        \n",
    "        print(\"[%.1f s] After %d epochs, hit@10 = %.3f, NDCG@10 = %.3f.\"%(time()-t1, ep, hits/6040, tNDCG/6040))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
